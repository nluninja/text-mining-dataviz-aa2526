{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning spaCy NER for Nutrition Product Entities\n",
    "\n",
    "In this notebook, we'll learn how to **fine-tune a spaCy Named Entity Recognition (NER) model** to recognize domain-specific entities in nutrition supplement product descriptions.\n",
    "\n",
    "## Use Case\n",
    "We want to extract key information from nutrition product descriptions:\n",
    "- **PRODUCT**: Product names (e.g., \"Whey Protein Isolate 90\", \"Creatine Monohydrate\")\n",
    "- **INGREDIENT**: Active ingredients (e.g., \"BCAAs\", \"glutamic acid\", \"caffeine\")\n",
    "- **QUANTITY**: Amounts and measurements (e.g., \"23g of protein\", \"25g serving\")\n",
    "- **BENEFIT**: Health/fitness benefits (e.g., \"muscle growth\", \"recovery\")\n",
    "\n",
    "## Why Fine-Tune?\n",
    "Pre-trained spaCy models are trained on general text (news, web content) and don't recognize domain-specific entities well. Fine-tuning allows us to:\n",
    "1. Add new entity types specific to our domain\n",
    "2. Improve recognition of existing entity types in specialized contexts\n",
    "3. Create a model tailored to our specific application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"spaCy version: {spacy.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset\n",
    "\n",
    "We'll use the GoNutrition product descriptions dataset, which contains detailed information about nutrition supplements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../02-Text_Classification/gonutrition.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at one product description\n",
    "print(\"Product:\", df.iloc[0]['product_name'])\n",
    "print(\"\\nDescription (first 1000 chars):\")\n",
    "print(df.iloc[0]['product_description'][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test the Pre-trained Model\n",
    "\n",
    "Let's see how well the default spaCy model recognizes entities in our domain-specific text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Helper function to display entities\n",
    "def show_ents(doc):\n",
    "    \"\"\"Display entities found in a document.\"\"\"\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(f\"{ent.text:30} | {ent.label_:10} | {spacy.explain(ent.label_)}\")\n",
    "    else:\n",
    "        print('No named entities found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a nutrition-related sentence\n",
    "test_text = \"Whey Protein Isolate 90 provides 23g of protein per 25g serving with BCAAs and glutamic acid for muscle growth.\"\n",
    "doc = nlp(test_text)\n",
    "\n",
    "print(\"Test text:\")\n",
    "print(test_text)\n",
    "print(\"\\nEntities found by pre-trained model:\")\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with displaCy\n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the pre-trained model doesn't recognize:\n",
    "- \"Whey Protein Isolate 90\" as a PRODUCT\n",
    "- \"BCAAs\" or \"glutamic acid\" as INGREDIENTs\n",
    "- \"muscle growth\" as a BENEFIT\n",
    "\n",
    "**This is why we need to fine-tune!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Training Data\n",
    "\n",
    "spaCy requires training data in a specific format:\n",
    "```python\n",
    "(\"text\", {\"entities\": [(start, end, \"LABEL\"), ...]})\n",
    "```\n",
    "\n",
    "We'll manually annotate some examples from our dataset. In production, you would use annotation tools like:\n",
    "- [Prodigy](https://prodi.gy/) (by spaCy creators)\n",
    "- [Label Studio](https://labelstud.io/)\n",
    "- [Doccano](https://github.com/doccano/doccano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our custom entity labels\n",
    "CUSTOM_LABELS = [\"PRODUCT\", \"INGREDIENT\", \"QUANTITY\", \"BENEFIT\"]\n",
    "\n",
    "# Manually annotated training data\n",
    "# Format: (text, {\"entities\": [(start_char, end_char, label), ...]})\n",
    "TRAIN_DATA = [\n",
    "    (\n",
    "        \"Whey Protein Isolate 90 provides 23g of protein per 25g serving.\",\n",
    "        {\"entities\": [(0, 23, \"PRODUCT\"), (33, 47, \"QUANTITY\"), (52, 63, \"QUANTITY\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"This whey protein isolate powder is 90% protein and extremely low in fat.\",\n",
    "        {\"entities\": [(5, 27, \"PRODUCT\"), (36, 47, \"QUANTITY\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"It's packed with BCAAs and glutamic acid for muscle growth and recovery.\",\n",
    "        {\"entities\": [(17, 22, \"INGREDIENT\"), (27, 40, \"INGREDIENT\"), (45, 58, \"BENEFIT\"), (63, 71, \"BENEFIT\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"Creatine Monohydrate helps increase power and strength during high intensity exercise.\",\n",
    "        {\"entities\": [(0, 20, \"PRODUCT\"), (36, 41, \"BENEFIT\"), (46, 54, \"BENEFIT\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"Beta Alanine has been shown to increase carnosine production.\",\n",
    "        {\"entities\": [(0, 12, \"INGREDIENT\"), (40, 49, \"INGREDIENT\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"Volt pre workout formula includes 12 advanced active ingredients with 389mg of caffeine.\",\n",
    "        {\"entities\": [(0, 4, \"PRODUCT\"), (70, 87, \"QUANTITY\"), (79, 87, \"INGREDIENT\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"Take 5g of Creatine Monohydrate to improve lean muscle gains.\",\n",
    "        {\"entities\": [(5, 7, \"QUANTITY\"), (11, 31, \"PRODUCT\"), (44, 61, \"BENEFIT\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"GN Whey Protein 80 contains 20g of premium grade protein per 25g serving.\",\n",
    "        {\"entities\": [(0, 18, \"PRODUCT\"), (28, 51, \"QUANTITY\"), (56, 73, \"QUANTITY\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"L Taurine and Beta Alanine work to reduce muscular fatigue and soreness.\",\n",
    "        {\"entities\": [(0, 9, \"INGREDIENT\"), (14, 26, \"INGREDIENT\"), (42, 58, \"BENEFIT\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"Our protein powder helps with faster recovery and muscle repair.\",\n",
    "        {\"entities\": [(4, 18, \"PRODUCT\"), (30, 46, \"BENEFIT\"), (51, 64, \"BENEFIT\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"Arginine Alpha Ketoglutarate enhances nitric oxide production for better pump.\",\n",
    "        {\"entities\": [(0, 27, \"INGREDIENT\"), (37, 49, \"INGREDIENT\"), (65, 77, \"BENEFIT\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"Citrulline Malate at 4g per serving can increase training intensity.\",\n",
    "        {\"entities\": [(0, 17, \"INGREDIENT\"), (21, 35, \"QUANTITY\"), (49, 68, \"BENEFIT\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"Vitamin B6 and guarana extract provide energy and mental focus.\",\n",
    "        {\"entities\": [(0, 10, \"INGREDIENT\"), (15, 30, \"INGREDIENT\"), (39, 45, \"BENEFIT\"), (50, 62, \"BENEFIT\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"Each scoop contains 22g of whey protein isolate with essential amino acids.\",\n",
    "        {\"entities\": [(20, 48, \"QUANTITY\"), (27, 48, \"PRODUCT\"), (54, 74, \"INGREDIENT\")]}\n",
    "    ),\n",
    "    (\n",
    "        \"ZMA zinc and magnesium formula supports normal testosterone production.\",\n",
    "        {\"entities\": [(0, 3, \"PRODUCT\"), (4, 8, \"INGREDIENT\"), (13, 22, \"INGREDIENT\"), (40, 70, \"BENEFIT\")]}\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"Created {len(TRAIN_DATA)} training examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's verify our annotations are correct\n",
    "def verify_annotations(train_data):\n",
    "    \"\"\"Verify that annotation spans match the text.\"\"\"\n",
    "    for text, annotations in train_data:\n",
    "        for start, end, label in annotations[\"entities\"]:\n",
    "            span_text = text[start:end]\n",
    "            print(f\"{label:12} | '{span_text}'\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Check first 3 examples\n",
    "print(\"Verifying annotations (first 3 examples):\")\n",
    "print(\"=\" * 40)\n",
    "verify_annotations(TRAIN_DATA[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the Training Pipeline\n",
    "\n",
    "We have two options for fine-tuning:\n",
    "1. **Update existing model**: Add new entity types to a pre-trained model\n",
    "2. **Train from blank**: Create a new model from scratch\n",
    "\n",
    "We'll use option 1 (updating an existing model) since we want to keep the model's existing capabilities while adding our custom entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_model(base_model=\"en_core_web_sm\", custom_labels=None):\n",
    "    \"\"\"\n",
    "    Create a model for training by loading a base model and adding custom NER labels.\n",
    "    \n",
    "    Args:\n",
    "        base_model: Name of the base spaCy model to use\n",
    "        custom_labels: List of custom entity labels to add\n",
    "    \n",
    "    Returns:\n",
    "        spaCy nlp object ready for training\n",
    "    \"\"\"\n",
    "    # Load the base model\n",
    "    nlp = spacy.load(base_model)\n",
    "    \n",
    "    # Get the NER component\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.add_pipe(\"ner\", last=True)\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    # Add custom labels\n",
    "    if custom_labels:\n",
    "        for label in custom_labels:\n",
    "            ner.add_label(label)\n",
    "            print(f\"Added label: {label}\")\n",
    "    \n",
    "    return nlp\n",
    "\n",
    "# Create the model\n",
    "nlp_train = create_training_model(custom_labels=CUSTOM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all labels in the model\n",
    "ner = nlp_train.get_pipe(\"ner\")\n",
    "print(\"All NER labels in the model:\")\n",
    "for label in ner.labels:\n",
    "    print(f\"  - {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Convert Training Data to spaCy Format\n",
    "\n",
    "We need to convert our training data to spaCy's `Example` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_examples(nlp, train_data):\n",
    "    \"\"\"\n",
    "    Convert training data to spaCy Example objects.\n",
    "    \n",
    "    Args:\n",
    "        nlp: spaCy nlp object\n",
    "        train_data: List of (text, annotations) tuples\n",
    "    \n",
    "    Returns:\n",
    "        List of Example objects\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    for text, annotations in train_data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "# Create examples\n",
    "train_examples = create_examples(nlp_train, TRAIN_DATA)\n",
    "print(f\"Created {len(train_examples)} training examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Model\n",
    "\n",
    "Now we'll train the NER component with our custom data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ner(nlp, train_examples, n_iter=30, drop=0.5):\n",
    "    \"\"\"\n",
    "    Train the NER component of a spaCy model.\n",
    "    \n",
    "    Args:\n",
    "        nlp: spaCy nlp object\n",
    "        train_examples: List of Example objects\n",
    "        n_iter: Number of training iterations\n",
    "        drop: Dropout rate for regularization\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of training losses\n",
    "    \"\"\"\n",
    "    # Get the NER component\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    # Disable other pipeline components during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    \n",
    "    losses_history = []\n",
    "    \n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        # Initialize the model with examples\n",
    "        optimizer = nlp.initialize(lambda: train_examples)\n",
    "        \n",
    "        print(\"Training the NER model...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for iteration in range(n_iter):\n",
    "            # Shuffle training data\n",
    "            random.shuffle(train_examples)\n",
    "            losses = {}\n",
    "            \n",
    "            # Create minibatches\n",
    "            batches = minibatch(train_examples, size=compounding(4.0, 32.0, 1.001))\n",
    "            \n",
    "            for batch in batches:\n",
    "                nlp.update(\n",
    "                    batch,\n",
    "                    drop=drop,\n",
    "                    sgd=optimizer,\n",
    "                    losses=losses\n",
    "                )\n",
    "            \n",
    "            losses_history.append(losses.get('ner', 0))\n",
    "            \n",
    "            # Print progress every 5 iterations\n",
    "            if (iteration + 1) % 5 == 0:\n",
    "                print(f\"Iteration {iteration + 1:3d}/{n_iter} | Loss: {losses.get('ner', 0):.4f}\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Training complete!\")\n",
    "    \n",
    "    return losses_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Train the model\n",
    "losses = train_ner(nlp_train, train_examples, n_iter=30, drop=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, marker='o', markersize=3)\n",
    "plt.title('NER Training Loss Over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate the Fine-Tuned Model\n",
    "\n",
    "Let's test our fine-tuned model on the same text we tested earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on the same text as before\n",
    "test_text = \"Whey Protein Isolate 90 provides 23g of protein per 25g serving with BCAAs and glutamic acid for muscle growth.\"\n",
    "doc = nlp_train(test_text)\n",
    "\n",
    "print(\"Test text:\")\n",
    "print(test_text)\n",
    "print(\"\\nEntities found by FINE-TUNED model:\")\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with displaCy\n",
    "# Define custom colors for our new labels\n",
    "colors = {\n",
    "    \"PRODUCT\": \"#7aecec\",      # Light blue\n",
    "    \"INGREDIENT\": \"#bfeeb7\",   # Light green  \n",
    "    \"QUANTITY\": \"#feca74\",     # Orange\n",
    "    \"BENEFIT\": \"#ff9561\"       # Coral\n",
    "}\n",
    "\n",
    "options = {\"ents\": CUSTOM_LABELS + [\"MONEY\", \"ORG\", \"GPE\", \"DATE\"], \"colors\": colors}\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on new, unseen text\n",
    "test_texts = [\n",
    "    \"Add 10g of BCAA powder to your post-workout shake for enhanced recovery.\",\n",
    "    \"Our Mass Gainer contains 50g of protein and 250g of carbohydrates per serving.\",\n",
    "    \"Caffeine and taurine boost energy levels and mental alertness during training.\",\n",
    "    \"Take Omega-3 Fish Oil daily for joint health and reduced inflammation.\"\n",
    "]\n",
    "\n",
    "print(\"Testing on unseen text:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for text in test_texts:\n",
    "    doc = nlp_train(text)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(\"Entities:\")\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(f\"  - {ent.text} ({ent.label_})\")\n",
    "    else:\n",
    "        print(\"  No entities found\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test on Actual Product Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a real product description from our dataset\n",
    "# Take a snippet from the first product\n",
    "sample_text = df.iloc[0]['product_description'][:500]\n",
    "\n",
    "doc = nlp_train(sample_text)\n",
    "\n",
    "print(\"Sample from dataset:\")\n",
    "print(\"=\" * 60)\n",
    "print(sample_text)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nEntities found:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"  {ent.label_:12} | {ent.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the entities in the product description\n",
    "displacy.render(doc, style='ent', jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save the Fine-Tuned Model\n",
    "\n",
    "Let's save our model so we can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"./nutrition_ner_model\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "nlp_train.to_disk(output_dir)\n",
    "print(f\"Model saved to: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the saved model\n",
    "nlp_loaded = spacy.load(output_dir)\n",
    "\n",
    "# Verify it works\n",
    "test_doc = nlp_loaded(\"Creatine Monohydrate provides 5g per serving for strength gains.\")\n",
    "print(\"Testing loaded model:\")\n",
    "for ent in test_doc.ents:\n",
    "    print(f\"  {ent.label_:12} | {ent.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Entity Extraction Pipeline\n",
    "\n",
    "Let's create a function to extract structured information from product descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nutrition_entities(text, nlp):\n",
    "    \"\"\"\n",
    "    Extract nutrition-related entities from text.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to process\n",
    "        nlp: Trained spaCy model\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with extracted entities by type\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    entities = {\n",
    "        \"products\": [],\n",
    "        \"ingredients\": [],\n",
    "        \"quantities\": [],\n",
    "        \"benefits\": []\n",
    "    }\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PRODUCT\":\n",
    "            entities[\"products\"].append(ent.text)\n",
    "        elif ent.label_ == \"INGREDIENT\":\n",
    "            entities[\"ingredients\"].append(ent.text)\n",
    "        elif ent.label_ == \"QUANTITY\":\n",
    "            entities[\"quantities\"].append(ent.text)\n",
    "        elif ent.label_ == \"BENEFIT\":\n",
    "            entities[\"benefits\"].append(ent.text)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    for key in entities:\n",
    "        entities[key] = list(dict.fromkeys(entities[key]))\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all products in the dataset\n",
    "print(\"Extracting entities from all products:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    entities = extract_nutrition_entities(row['product_description'][:1000], nlp_train)\n",
    "    \n",
    "    print(f\"\\n{row['product_name']}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"  Products:    {entities['products'][:5]}\")\n",
    "    print(f\"  Ingredients: {entities['ingredients'][:5]}\")\n",
    "    print(f\"  Quantities:  {entities['quantities'][:5]}\")\n",
    "    print(f\"  Benefits:    {entities['benefits'][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Next Steps\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Why fine-tuning matters**: Pre-trained models don't recognize domain-specific entities\n",
    "2. **Data preparation**: How to format training data with entity annotations\n",
    "3. **Model training**: How to update a spaCy model with new entity types\n",
    "4. **Evaluation**: Testing the model on seen and unseen data\n",
    "5. **Deployment**: Saving and loading trained models\n",
    "\n",
    "### Improving the Model\n",
    "\n",
    "To improve accuracy, you should:\n",
    "\n",
    "1. **Add more training data**: 15 examples is minimal; aim for 100+ annotated examples\n",
    "2. **Use annotation tools**: Prodigy or Label Studio for efficient annotation\n",
    "3. **Include negative examples**: Text without entities to reduce false positives\n",
    "4. **Increase iterations**: More training epochs (with more data)\n",
    "5. **Use a larger base model**: Try `en_core_web_lg` for better embeddings\n",
    "\n",
    "### spaCy 3.x Config System\n",
    "\n",
    "For production use, spaCy 3.x recommends using the config-based training system:\n",
    "\n",
    "```bash\n",
    "python -m spacy init config config.cfg --lang en --pipeline ner\n",
    "python -m spacy train config.cfg --output ./output --paths.train ./train.spacy\n",
    "```\n",
    "\n",
    "This provides better reproducibility and more training options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison: pre-trained vs fine-tuned\n",
    "nlp_pretrained = spacy.load('en_core_web_sm')\n",
    "\n",
    "comparison_text = \"Take 5g of Creatine Monohydrate and BCAAs daily for muscle growth and faster recovery.\"\n",
    "\n",
    "print(\"COMPARISON: Pre-trained vs Fine-tuned Model\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nText: {comparison_text}\")\n",
    "\n",
    "print(\"\\n--- Pre-trained Model ---\")\n",
    "doc_pre = nlp_pretrained(comparison_text)\n",
    "if doc_pre.ents:\n",
    "    for ent in doc_pre.ents:\n",
    "        print(f\"  {ent.label_:12} | {ent.text}\")\n",
    "else:\n",
    "    print(\"  No entities found\")\n",
    "\n",
    "print(\"\\n--- Fine-tuned Model ---\")\n",
    "doc_fine = nlp_train(comparison_text)\n",
    "if doc_fine.ents:\n",
    "    for ent in doc_fine.ents:\n",
    "        print(f\"  {ent.label_:12} | {ent.text}\")\n",
    "else:\n",
    "    print(\"  No entities found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Add more training data**: Annotate 10 more sentences from the product descriptions and retrain the model\n",
    "\n",
    "2. **Add a new entity type**: Add a \"DOSAGE\" entity type to capture recommended dosages (e.g., \"2-5 servings per day\")\n",
    "\n",
    "3. **Evaluate quantitatively**: Split your data into train/test sets and calculate precision, recall, and F1 scores\n",
    "\n",
    "4. **Try different base models**: Compare results using `en_core_web_sm`, `en_core_web_md`, and `en_core_web_lg`\n",
    "\n",
    "5. **Build an application**: Create a simple function that takes a product description URL and returns structured product information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
